import numpy as np
import pandas as pd
import nltk
import re
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import PassiveAggressiveClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Download NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Initialize lemmatizer
lemmatizer = WordNetLemmatizer()

class NewsClassifier:
    """
    A fake news classifier that uses NLP and machine learning to detect fake news articles.
    """
    
    def __init__(self):
        self.vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
        self.model = PassiveAggressiveClassifier(max_iter=1000)
        self.stop_words = set(stopwords.words('english'))
    
    def load_dataset(self, file_path='fake_news_dataset.csv'):
        """
        Load dataset from CSV file
        """
        try:
            data = pd.read_csv(file_path)
            print(f"\nDataset loaded successfully with {len(data)} records")
            return data
        except Exception as e:
            print(f"\nError loading dataset: {e}")
            return None
    
    def clean_text(self, text):
        """
        Clean and preprocess text data
        """
        # Convert to lowercase
        text = text.lower()
        
        # Remove URLs
        text = re.sub(r'http\S+', '', text)
        
        # Remove punctuation
        text = text.translate(str.maketrans('', '', string.punctuation))
        
        # Remove numbers
        text = re.sub(r'\d+', '', text)
        
        # Tokenize text
        words = word_tokenize(text)
        
        # Remove stopwords and lemmatize
        words = [lemmatizer.lemmatize(word) for word in words if word not in self.stop_words]
        
        # Join words back to text
        cleaned_text = ' '.join(words)
        
        return cleaned_text
    
    def preprocess_data(self, data):
        """
        Preprocess the entire dataset
        """
        # Check for missing values
        print("\nChecking for missing values:")
        print(data.isnull().sum())
        
        # Drop missing values
        data = data.dropna()
        
        # Clean text data
        print("\nCleaning text data...")
        data['cleaned_text'] = data['text'].apply(self.clean_text)
        
        return data
    
    def visualize_data(self, data):
        """
        Visualize the class distribution
        """
        plt.figure(figsize=(8, 6))
        sns.countplot(x='label', data=data)
        plt.title('Distribution of Real vs Fake News')
        plt.xlabel('Label (0: Real, 1: Fake)')
        plt.ylabel('Count')
        plt.show()
    
    def train_model(self, X_train, y_train):
        """
        Train the classification model
        """
        print("\nTraining the model...")
        # Vectorize text data
        X_train_vectorized = self.vectorizer.fit_transform(X_train)
        
        # Train the model
        self.model.fit(X_train_vectorized, y_train)
        
        print("Model training complete!")
        return X_train_vectorized
    
    def evaluate_model(self, X_test, y_test):
        """
        Evaluate model performance
        """
        # Vectorize test data
        X_test_vectorized = self.vectorizer.transform(X_test)
        
        # Make predictions
        y_pred = self.model.predict(X_test_vectorized)
        
        # Calculate accuracy
        accuracy = accuracy_score(y_test, y_pred)
        print(f"\nModel Accuracy: {accuracy*100:.2f}%")
        
        # Confusion matrix
        conf_matrix = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted Label')
        plt.ylabel('True Label')
        plt.show()
        
        return accuracy
    
    def save_model(self, model_file='fake_news_model.pkl', vectorizer_file='tfidf_vectorizer.pkl'):
        """
        Save the trained model and vectorizer
        """
        joblib.dump(self.model, model_file)
        joblib.dump(self.vectorizer, vectorizer_file)
        print(f"\nModel saved to {model_file}")
        print(f"Vectorizer saved to {vectorizer_file}")
    
    def load_saved_model(self, model_file='fake_news_model.pkl', vectorizer_file='tfidf_vectorizer.pkl'):
        """
        Load saved model and vectorizer
        """
        try:
            self.model = joblib.load(model_file)
            self.vectorizer = joblib.load(vectorizer_file)
            print("\nModel and vectorizer loaded successfully!")
            return True
        except Exception as e:
            print(f"\nError loading saved model: {e}")
            return False
    
    def predict_news(self, news_text):
        """
        Predict if a news article is real or fake
        """
        # Clean the input text
        cleaned_text = self.clean_text(news_text)
        
        # Vectorize the text
        vectorized_text = self.vectorizer.transform([cleaned_text])
        
        # Make prediction
        prediction = self.model.predict(vectorized_text)
        
        # Get prediction probability
        proba = self.model._predict_proba_lr(vectorized_text)[0]
        
        result = {
            'prediction': 'Fake' if prediction[0] == 1 else 'Real',
            'confidence': max(proba) * 100,
            'text': news_text[:150] + '...' if len(news_text) > 150 else news_text
        }
        
        return result

def test_model(classifier):
    """
    Test the model with sample news articles
    """
    # Sample news articles (real and fake)
    test_articles = [
        "Scientists confirm that climate change is accelerating at an unprecedented rate based on new data from NASA satellites.",
        "Breaking: Celebrity couple announces divorce after just 3 months of marriage (this is completely fabricated).",
        "New study shows that drinking coffee can significantly improve your longevity.",
        "The government is secretly implanting microchips in COVID-19 vaccines to track citizens."
    ]
    
    print("\nTesting model with sample news articles:")
    for article in test_articles:
        result = classifier.predict_news(article)
        print(f"\nText: {result['text']}")
        print(f"Prediction: {result['prediction']} (Confidence: {result['confidence']:.2f}%)")

def main():
    """
    Main function to run the fake news detector
    """
    # Initialize the classifier
    classifier = NewsClassifier()
    
    print("""
    =============================================
           FAKE NEWS DETECTOR - MAIN MENU
    =============================================
    """)
    
    while True:
        print("\nOptions:")
        print("1. Train a new model")
        print("2. Load and test saved model")
        print("3. Test with custom news text")
        print("4. Exit")
        
        choice = input("\nEnter your choice (1-4): ")
        
        if choice == '1':
            # Train a new model
            data = classifier.load_dataset()
            if data is not None:
                data = classifier.preprocess_data(data)
                classifier.visualize_data(data)
                
                # Split data into train and test sets
                X_train, X_test, y_train, y_test = train_test_split(
                    data['cleaned_text'], data['label'], test_size=0.2, random_state=42
                )
                
                # Train and evaluate model
                classifier.train_model(X_train, y_train)
                classifier.evaluate_model(X_test, y_test)
                
                # Save the trained model
                save_choice = input("\nDo you want to save this model? (y/n): ")
                if save_choice.lower() == 'y':
                    classifier.save_model()
                
                # Test with sample articles
                test_model(classifier)
        
        elif choice == '2':
            # Load and test saved model
            if classifier.load_saved_model():
                test_model(classifier)
        
        elif choice == '3':
            # Test with custom news text
            if hasattr(classifier, 'model') and classifier.model is not None:
                news_text = input("\nEnter the news text to classify: ")
                result = classifier.predict_news(news_text)
                print(f"\nPrediction: {result['prediction']} (Confidence: {result['confidence']:.2f}%)")
            else:
                print("\nPlease train or load a model first!")
        
        elif choice == '4':
            print("\nExiting Fake News Detector. Goodbye!")
            break
        
        else:
            print("\nInvalid choice. Please try again.")

if __name__ == '__main__':
    main()
